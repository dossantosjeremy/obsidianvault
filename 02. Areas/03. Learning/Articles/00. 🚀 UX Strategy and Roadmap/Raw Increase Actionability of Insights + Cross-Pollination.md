**# Resources

- Mentoring Guides - Mentorcruise
    
- How to Create a UX Project Plan
    
- UX Research Strategy - How to start setting priorities
    
- Tracking gold, silver and bronze ux research projects
    
- Research prioritization Gitlab
    
- UX Researcher Pairings
    

  
  

- Competency framework at Gitlab: [https://handbook.gitlab.com/job-families/product/ux-research-manager/](https://handbook.gitlab.com/job-families/product/ux-research-manager/)
    

  
  
  

|                                                                                                                                                                                                  |          |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------- |
| Article                                                                                                                                                                                          | State    |
| [UX Research Excellence Framework](https://gqzhang.medium.com/ux-research-excellence-framework-a824928fd7e9)                                                                                     | Approuvé |
| [10 Metrics to Track the ROI of UX Efforts – MeasuringU](https://measuringu.com/ux-roi/)                                                                                                         | Approuvé |
| [A Framework for Demonstrating Research Impact \| Sprig](https://sprig.com/blog/framework-for-demonstrating-research-impact)                                                                     | Approuvé |
| [Example impact maps](https://www.impactmapping.org/example.html)                                                                                                                                | Approuvé |
| [How to measure UX research impact: A multi-level framework - UXinsight](https://uxinsight.org/how-to-measure-ux-research-impact-a-multi-level-framework/)                                       | Approuvé |
| [Tracking the impact of UX Research: a framework \| by Caitlin Sullivan](https://uxdesign.cc/tracking-the-impact-of-ux-research-a-framework-9e8b8f51599b)                                        | Approuvé |
| [Three levels of UX Research impact \| by Tao Dong](https://uxdesign.cc/three-levels-of-ux-research-impact-174768b7f4ef)                                                                         | Approuvé |
| [How to measure UX research impact: A multi-level framework - UXinsight](https://uxinsight.org/how-to-measure-ux-research-impact-a-multi-level-framework/)                                       | Approuvé |
| [Turn User Research Data Analysis into Actionable UX Insights in 5 Steps \| Komodo Digital](https://www.komododigital.co.uk/insights/turn-user-research-data-analysis-into-actionable-insights/) | Approuvé |
| [Research insights \| GitLab](https://about.gitlab.com/handbook/product/ux/ux-research/research-insights/)                                                                                       | Approuvé |
|                                                                                                                                                                                                  |          |

  

# Increase actionability of UX Insights

  

[UX Research Excellence Framework](https://gqzhang.medium.com/ux-research-excellence-framework-a824928fd7e9) 

  
  

Prioritizing requests when they come to us

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXc4vS2oV0at8ZnWrl1CbP1iVht8rHbgkaFpQSWECSiqbvh1TczeVgkoz_Q8Ti1t0Jay0qPAIIa73Wf2wGojFOrFIwtBTwUECcyHVLRlfBcgilrOB1_w2xvzuUq4LymBODkjwvDoDiUtMxBm7ayPjHLsdfT5?key=VoNDMtukhSHpSBoZ7bNXlevl)

  
  

- Prioritise based on some criteria. Use Likert scales to assign values to each (e.g. Customer Impact). 
    
- Impact matrix: What kind of project can be done by the research team over the course of a year. 
    

  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXf_LW9q5XrbC6DnOCXVD4hg2cm5hyL4BP758Vo8SHmqi_OqdVhLQ_Sc0aoR_TxZenz9MFhns-CPHSZE0gLMuj2enyc2DCnh9-WjkudZE2a051jpdLkHzqbUy7OdtDZzatrI1TZkj5Pi5vn9WdBclvn15rgS?key=VoNDMtukhSHpSBoZ7bNXlevl)

  

Applying the right research method

- 2 lenses to assess and select the right research method
    

- Reliability and validity of a specific method
    
- Simplicity and scalability of how it is applied. 
    

  
  

Similarly as a UX researcher, we need to make sure the research methods we choose are working on the key problems of a situation, and make sure it is precisely measuring the right UX aspects. If we use a method that is both valid and reliable, other researchers can easily repeat and replicate our research to get similar results.

  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcjVtBKFqvrTkmdfN4lkW3I85jdT3vP1OQVUe_6kcDn0Hg8Z5jt-0TD-DnS02o_E3sA8edRo3H1PONXxei26se148Pl65liIp11K1jWiAh3UXL39Jw6bsli29W9HhneVjx-TuHhpguuPsKzo2R76duYXYg?key=VoNDMtukhSHpSBoZ7bNXlevl)

We always encourage the team to follow the principle of parsimony, or the Occam’s Razor principle. When you select a method for a product situation, we recommend you start from the key problems and select one method to begin with. Then you add another method only when it’s absolutely necessary and you have strong rationales to add it. We value a researcher because she or he uses the simplest method to solve the most complex problems, not the other way around.

  

Precise and timely documentation of research methods, processes and participants in each project

At Uber, we encouraged precise and timely documentation of research methods, processes and participants in each project, so that other researchers can repeat and replicate it. 

  
  

Review all past projects and consolidate everything. 

We reviewed past projects, including successes and failures, highs and lows, delays and cancelations. We white-boarded the practices and processes, reflected the ups and downs along the co-riding journey, and came out with a How-We-Work Partnership Journey. This journey map consolidates the five major phases in a typical product development lifecycle, clarifies how different functions work all together but at different phases each function plays different roles.

  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeZyW1nB2nk2Q3qRu8cOnKNVM9gLXQwxWb4Pvn97JPd8oC5T2WF2EAUDEAAJIg9FL3ZwaeYzqvHFva113R6WDkbfjT0B7gmzVQ0heYCLLxHuLdJHuHaFDBR-EK4gMDV2whaSMW57T044HN6QfwDM_93-rDH?key=VoNDMtukhSHpSBoZ7bNXlevl)

we also find case after case that UX researchers are called in too late because the solutions are not solving the real user problems in the first place. We call them “misplaced solutions.”

  
  
  

Framework

- Impact: Where and When 
    

- Prioritizing work
    
- Impact Matrix
    

- Method
    

- Reliable and valid
    
- Simple and scalable
    

- Work together (Partnership)
    

- Cross functions
    
- Early in process
    

  
  
  

[10 Metrics to Track the ROI of UX Efforts – MeasuringU](https://measuringu.com/ux-roi/) 

  

More for eCommerce: 

- Purchase rate
    
- Total Number of Purchase/Transactions
    
- Average Order Value
    
- Reduced Cart Abandonment Rate
    
- Reduced calls to support
    
- Registrations
    
- Click-Through Rate
    
- Time on Site/Engagement
    
- Number of return visitors
    
- Net promoter score
    

  
  
  

[A Framework for Demonstrating Research Impact | Sprig](https://sprig.com/blog/framework-for-demonstrating-research-impact) 

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfa_n1CZYMILVuH3MDtR-OYlH-f96zUtiPUaiRvZmQ0feV3MDmUvnqsz33JVhN_Y74ikU0kWXHeUnNU-yEGBKsprqH7FjBMYyucp0ZVeJCaHDgx2tLUYDgK94JQ4DGmMZw5D9cNFWZ-sSb1I41Hskqy_Bg?key=VoNDMtukhSHpSBoZ7bNXlevl)

UX Metrics

  

[Example impact maps](https://www.impactmapping.org/example.html) 

Impact map

- Connection between business goals, impacts on users and stakeholders and team deliverables
    
- Takes the form of a mindmap, hierarchical outline
    

  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcD_1X_UoJtepRy28JvsEG6S5MhQfO59jg-cOWMNM9-_4CmzZQphiiOCoBaVQRvxbB0RPiA145li6pDtV-k_4GZWpi0KoSZSlEQGpUlqs_-W8hGP9U18mPztJA5Df1kFDoSguQEOYxOefrDMW1__44XeUI?key=VoNDMtukhSHpSBoZ7bNXlevl)

  
  
  
  
  
  
  

[Tracking the impact of UX Research: a framework | by Caitlin Sullivan](https://uxdesign.cc/tracking-the-impact-of-ux-research-a-framework-9e8b8f51599b)

- Influence on product decisions (design changes and strategy updates)
    
- Research shared in communications (mentions of research which can influence stakeholders’ exposure)
    
- Requests for collaboration
    
- Development of a UX Research infrastructure
    

  

Store everything in a spreadsheet

Bottom-up approach. 

  

Record the impact

- What happened
    
- When did it happen
    
- Where did it happen
    
- What are the metrics
    

  

Note the research source and type

- Sharinf a single insight in slack
    
- Workshop
    
- Sharing learnings… 
    
- Categorise the research type:
    

- Evaluative
    
- Generative
    
- Iterative
    

  

Type of research impact

- Influence on product decisions
    
- Research shared in communications
    
- Prompts for collaborations
    
- Development of UX Research Infrastructure
    

  

- Add a metric as a sort of proof. 
    

- E.g.: “On a scale of 1–7, how quickly were you able to make that decision after hearing that insight?” (Where 1 was not quickly and 7 was quickly).
    
- Use a quote from a stakeholder. 
    

  

Record the team on which we had impact.

  

Note the impact’s scale

- Stakeholders
    
- Team
    
- organization / company 
    

  

Track the dates of the presentations, research, follow-ups… 

  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXd8_Vw_fpsEpZl83KD5OEL42FIWyikDJh-N5mbXKm5Sa-CYu4tub0BMfQolz4Pg8RyFBMW2diKH0QQ_rbmzN-ZwGTNEfuqHFgjMCQVrdzOoYsOsKolkFJHFrbVMESIp51nz8_UY3hvNwkZ7Z-Ppq27088M?key=VoNDMtukhSHpSBoZ7bNXlevl)

  
  

 [Three levels of UX Research impact | by Tao Dong](https://uxdesign.cc/three-levels-of-ux-research-impact-174768b7f4ef) 

- producing knowledge about product users and product designs to support decision making. 
    
- Level 1: Research questions answered
    
- Level 2: Decisions supported
    
- Level 3: User value generated.
    

  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfn8WRDuvy83lV6BRgxSF36SiOFlFOUbnMuldzzfjESacAZ6KhMzIH0Aag85fAh6QHrqBYBGMcu6DlbiZ33nT-Vb6CzHIsElZZZV6PvOe7-O_v8iJnAnGOV3rh_0Zdq3sAYw2PBSzmLBFxFORC6SW5ymmom?key=VoNDMtukhSHpSBoZ7bNXlevl)

  
  
  
  
  
  
  

[How to measure UX research impact: A multi-level framework - UXinsight](https://uxinsight.org/how-to-measure-ux-research-impact-a-multi-level-framework/)

  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeZkUqFmY3XCkUkHxbLFWafUYF8amqeA27hNRJFpMyTkA_GpHLcm-JVGNheLsXhTlbGqLgtOOd7fXcdDBTDuyWgDrcgjQoi8DZ7hj3lU8O-kxJwO-BYIJln7lWgAgXZAY2p2iSBXO-JmX0Z73EbdnF3RJA?key=VoNDMtukhSHpSBoZ7bNXlevl)

  
  
  

Summary

- Level 1: Impact on the customer and business outcome. 
    

- User Experience Outcomes
    

- Tracking UX Metrics to see if the changes we propose or implement influence user experience. 
    

- Business outcomes
    

- Impact on A/B Testing. 
    
- Number of dropouts, conversion, customer service contacts… 
    

- Level 2: Impact on the organization
    

- Organisational learning. Track how research impacts the strategic choices.  
    
- Engagement: [Stakeholders’ engagement with research](https://uxinsight.org/ux-research-training/facilitation-engaging-stakeholders-in-ux-research-projects/). 
    

- Level 3: Impact on the research practice
    

- Time spent on research
    
- Research activities we are doing
    
- Research headcount
    
- What point of the design process research is consulted
    
- Ratio between discovery and evaluative research
    

  
  

[Turn User Research Data Analysis into Actionable UX Insights in 5 Steps | Komodo Digital](https://www.komododigital.co.uk/insights/turn-user-research-data-analysis-into-actionable-insights/)

  

How to communicate insights to increase actionability. 

- Share the insights in a more digestible way. 
    
- Havea slide with all the insights synthesised as a problem statement
    

- You can format a problem statement using this formula:
    
- [User] needs [Need] because [Insight].
    

- HMW questions can help you frame your user research insights or problem statements better. They will also be beneficial in idea generation in the next stage of Design Thinking.
    
- Host a workshop: Interactive, Collaborative, and Sparks innovation. 
    
- It’s an opportunity to put the research insights in front of people to find a unique design solution. In workshops you can cover:
    

- Empathy Mapping
    
- User Journey Mapping
    
- User Persona Creation
    
- Asking the ‘5-Whys’
    

  
  

[Research insights | GitLab](https://about.gitlab.com/handbook/product/ux/ux-research/research-insights/)

- The research study will likely result in a list of observations, patterns, and behaviors related to a user's experience. The raw data from the study are the research findings.
    
- A list of findings, alone, is often not enough to fully communicate how users conceptualize a topic or why they experienced a certain struggle. Through analysis and synthesis of the data gathered in a research study, we are able to distill insights that connect the dots between related concerns and provide an additional layer of understanding. These synthesized research findings evolve into a cohesive collection of insights that enables stakeholders to make informed decisions. We support each insight with evidence that can be referenced during discussions, typically in the form of video clips, interview quotes, or statistical data.
    

  

At GitLab, we measure the impact of our research by:

  

- Distinguishing an insight as "actionable" or "informative"
    
- Making sure each actionable insight has a clear recommendation or action associated with it
    

  

Tracking the completion of actionable insights

There are two types of insights: Actionable and Informative.

  

- Actionable insights are findings that require an action to be taken to resolve them. These can include UI changes, feature additions, and even conducting additional research. All of these insights require the person conducting the research to create a GitLab issue that documents the actionable insight along with a proposed path for a solution.
    
- Informative insights are findings that provide additional insights into topics, but for which no action needs to be taken as there is nothing to resolve. Informative insights are created only in Dovetail.
    

  
  

Informative insights

- Informative insights help us learn about something or someone and don’t result in immediate action. Instead, these insights help build knowledge about our users, industries, competitors, and so on.
    

  

For example:

  

When documenting informative insights, no special actions or processes need to be followed. These simply get documented into Dovetail, per the standard process, or in a corresponding research report (e.g., in Google Slides). Include links to Dovetail or the research report in the research issue.

  
  

Actionable Insights

Actionable insights always have a follow-up action that needs to take place as a result of the research observation or data, and a clear recommendation or action associated with it. An actionable insight both defines the insight and clearly calls out the next step. Here are two different examples:

  

When creating an actionable insight issue to propose a change to a feature or product area under use, be cognizant of the wider impact of the changes on the top JTBDs associated with that area. If the data backing the insight does not provide enough confidence in the highlighted problem, take additional measures to validate it.

  

When you document an actionable insight, its three main components are:

  

- The insight itself: often the problem, finding, or observation.
    
- The “why”: supporting evidence that supports the insight. Often, it’s describing why the problem is happening, or more details behind the finding or observation.
    
- The action: the next step or action that needs to take place as a result of the research. The action should be clearly defined, achievable, and directly tied back to the insight.
    
- Tips for writing an actionable insight:
    
- Avoid using words like: consider, possibly, maybe, suggest, etc. People can interpret these actions as optional.
    
- Instead, use directive terminology, such as: conduct, explore, redesign, etc. These words contribute to a clear action that needs to be taken as a next step.
    

  

To document actionable insights:

  

- Step 1: If already documented in Dovetail as an insight, preface the actionable insight's title with 'ACTIONABLE:' and clearly describe the next action that needs to be taken. If you are putting insights in a research report instead of Dovetail for your project, skip this step.
    
- Step 2: Create a unique issue in GitLab.com/GitLab-org/gitlab using the appropriate Actionable Insight issue template:
    
- Actionable Insight - Exploration needed - This is an actionable research insight derived from a UX research study. To address this insight, further exploration is required. That might be in the form of follow-up research, design explorations, etc. This issue template includes the ~"Actionable Insight::Exploration needed" scoped label.
    
- Actionable Insight - Product change - This is an actionable research insight derived from a UX research study. To address this insight, a change to the product experience is required. This issue template includes the ~"Actionable Insight::Product change" scoped label. Note that the ~"SUS::Impacting" label and a severity label are both required for actionable insights that require product changes.
    

  

When closing an actionable insight issue, it’s important to document why it was closed and whether the original action was acted upon.

  

In some cases, no action will be taken for a number of reasons, such as low priority, too large of an effort, not technically feasible, and so on. Regardless of the reason, document the decisions in the issue when closing it.

  

To what kinds of validation research do actionable insights apply?

  

Both Problem Validation and Solution Validation need to follow the actionable insights documentation process if actionable insights are discovered. For example:

  

Problem Validation: If there are insights that result in additional research, a newly identified target for next steps, or an identified problem to address, those are actionable insights.

Solution Validation: If there are insights that uncover a usability issue, a pain point users may experience, or a design issue, those are actionable insights.

The above examples have one thing in common regardless of the kind of research: the insight is actionable, and therefore, must be documented as such.

  

Additionally, UX Scorecard testing can yield actionable insights. Since UX Scorecard testing is an expert review and/or heuristic evaluation, creating Dovetail insights may not be applicable. Instead, be sure to document the details in the GitLab issue using the actionable insight template in GitLab.com.

  

We label issues containing insights identified through customer calls differently than other insights, because they don't directly relate to UX research efforts or tracking. For issues that contain insights derived from customer calls (or other customer support channels), please use the ~"Customer feedback" label.

  

### Why we track actionable insights

Actionable insights are tracked at GitLab for:

- Accountability: If there’s something that needs to be done as a result of conducting research, it should be done. This process helps prevent those actionable insights from getting lost, dismissed, or taking too long to be acted upon.
    
- Measuring research impact: Presently, it’s difficult to accurately measure the impact of a research project on the product. Tracking actionable insights allows us to refer back to a particular research project, see what actions were identified as a result of the research findings, and determine what action was taken within the product since those actions were identified.
    

  

The following data is presently being tracked:

- Number of newly opened and closed actionable insights issues, by quarter
    

- How many new actionable insight issues were created, per quarter
    
- How many actionable insight issues were closed, per quarter - and why they were closed
    

- Average number of days it takes for an actionable insight issue to close to completion
    

- Important to understand how long it's taking to address actionable insights within the product
    

- Breakdown of all actionable insight issues, to date
    

- Provides us with an understanding of how many total actionable insights there are, broken down by open and closed statuses
    

  

The data for the above can be viewed for each actionable insight scoped label:

- [Actionable insight::Product change](https://app.periscopedata.com/app/gitlab/1076087/Actionable-Insights::Product-Change)
    
- [Actionable insight::Exploration needed](https://app.periscopedata.com/app/gitlab/1076091/Actionable-Insights::Exploration-Needed)
    

Over time, once there's enough data, we might be able to slice this data at the stage/group level to help us understand what is (or isn't) working well. Based on what we learn, we’ll iterate on the approach.

Future data tracking considerations for actionable insights:

- Number of total actionable insights currently open, no activity within the issue (>6 month of no activity)
    

- Total number of actionable insights that have not seen activity in at least a month. These actionable insights will be followed up to understand why there hasn’t been activity.
    

- Number of total of actionable insights currently open, activity within the issue (activity <=6 months ago)
    

- Total number of actionable insights that have seen activity within the past month. It’s implied that these are actively being addressed in some way and not discarded.
    

  
  

# UX Scorecard

  

[Category Maturity Scorecards | GitLab](https://about.gitlab.com/handbook/product/ux/category-maturity/category-maturity-scorecards/)

  

[How to Create a UX Scorecard (8 Steps)](https://dscout.com/people-nerds/ux-scorecard)

  
  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfczNt-Wl_eiJ_ZrwnRAsknXtkvaWierUCiaAaRGC8rFVAMpzvdaV5_FxUtQirSi2MckTFJpLm1WE_ujgq1rNDPwRVyi6aOcBVX_d6ocLdeAMzvgyck8yTvdu1i15cufrMEzrqKHfk61j1pXzgsVDTt_yA?key=VoNDMtukhSHpSBoZ7bNXlevl)

  

Using a scale of 1–10, we asked participants, “How confident are you that you completed your registration successfully?”

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

[How to Create a UX Scorecard (8 Steps)](https://dscout.com/people-nerds/ux-scorecard)

[https://www.canva.com/design/DAE69zdgIkU/806c4dqcSUR8DZxB36Eiyw/view?utm_content=DAE69zdgIkU&utm_campaign=designshare&utm_medium=link&utm_source=sharebutton&mode=preview](https://www.canva.com/design/DAE69zdgIkU/806c4dqcSUR8DZxB36Eiyw/view?utm_content=DAE69zdgIkU&utm_campaign=designshare&utm_medium=link&utm_source=sharebutton&mode=preview) 

  
  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXc25ecM_jTIRAKxcxauUZIUQEFJU90Vcfw7c2HXDrzo4eidLzHgtoQfK1cM3qmnMsAmJWKTTDAJnp-RforTrWymEVEwOAVgJWpUuEb297ouQ9trFUg_yqNvNkgiErEbn42fvdgfAcefbYLL_LItwkuQUUGJ?key=VoNDMtukhSHpSBoZ7bNXlevl)

  

Single Usability Metric

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeJRYokpC-VFLcf60unwFHiQBcVsz9bNl6bdjTgyBVc4fojIW5axwcaZfYIL6TvsdfuJCvM6AI8VTnSJg-1Xn_s1s7Zdo584bWCMaaPHAKY43bj24Qlxbd7W_4nhpzRL1XO_0jZYwj5IWLYbpnp7_YnuwM3?key=VoNDMtukhSHpSBoZ7bNXlevl)

  
  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdub0LuE8lzTA-L5-1S5Ez7BKJSL6GK9zW805Fh3pjLMZsLTHi7x9cjGxK8gRrPUl6C654TmzTwjZh0ZHO_MELBSK0QzEqL02J8mmxvYib6B9ArKeXHorrsDVtH3_b1RWTlejCNHLCYWCvcXnFUl0ejK4Hg?key=VoNDMtukhSHpSBoZ7bNXlevl)

# Cross-Pollination

  

[https://about.gitlab.com/handbook/product/ux/ux-research/research-insights/](https://about.gitlab.com/handbook/product/ux/ux-research/research-insights/)

  
  

#### Collating insights from multiple studies

Also known as [desk research or secondary research](https://www.nngroup.com/articles/secondary-research-in-ux/). Sometimes it can be helpful to summarize and collate existing research to have a broader picture of users outside of a specific study. Insights from past studies can serve as a foundation for future studies and provide a high level overview of user behaviors and mental models.

To document insights from multiples studies, [tag themes and create insights](https://about.gitlab.com/handbook/product/ux/dovetail/) within individual Dovetail projects. Create a separate Dovetail story or project to summarize findings from multiple studies. Create an issue in GitLab which outlines the collated research project. Within that issue, add relevant Dovetail links and related issues.

  
  

Maximize insights on UserTesting

[https://www.nngroup.com/articles/user-testing-stepped-tasks/](https://www.nngroup.com/articles/user-testing-stepped-tasks/) 

[https://www.userinterviews.com/blog/user-testing-questions](https://www.userinterviews.com/blog/user-testing-questions) 

[https://uxdesign.cc/a-beginners-guide-to-asking-follow-up-questions-in-user-interviews-2fbeba124712](https://uxdesign.cc/a-beginners-guide-to-asking-follow-up-questions-in-user-interviews-2fbeba124712) 

[https://blog.prototypr.io/what-is-atomic-research-e5d9fbc1285c](https://blog.prototypr.io/what-is-atomic-research-e5d9fbc1285c) 

[https://userresearchacademy.substack.com/p/write-impactful-user-research-insights](https://userresearchacademy.substack.com/p/write-impactful-user-research-insights) 

  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXf-Cf6Rb7GRh2HyFTDGQXetnxUSP9dHnnYxdgzpILFQ2H30QBXBEHnvM38v0r_Lh8nKkb3DA08S-Sg0vBS6Ch4zL3JzLDUlsAweMXrhiFP4SPmgyc5fjMegno6UvNp-ZVn8wDCMNwydvx2fcgqnnmGtiCw?key=VoNDMtukhSHpSBoZ7bNXlevl)**