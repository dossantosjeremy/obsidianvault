---
tags:
  - UX
  - strategy
  - Learning
---
https://www.nngroup.com/articles/ux-strategy/ 
https://www.nngroup.com/articles/strategy-study-guide/




# Reviewed so far
* 3 types of roadmaps in UX and Product
* 5 Prioritization Methods in UX
* The 6 steps to roadmapping

# To review
* CSD Matrix Framework
* Create a UX Vision Statement
* Write a Mission Statement
* Minimize design risk by focusing on outcomes not features
* Objectives and key results
* Using Prioritization Matrices to inform product decisions
* UX Roadmaps definitions and components
* UX Roadmaps who, when and how
* UX Strategy study guide

# Roadmaps

## 3 types of roadmaps in UX and Product
* Roadmaps including UX Can have 3 scopes
	* Product
	* Field
	* Specialty
	* 
* Roadmap:
	* Strategic
	* Living
	* Communicating the team future work and problems to solve
	* Single source of truth
	* Represents the UX North Star
	* Meant to communicate the vision: What problems need to be solved. 
	* Roadmaps: Not a list of task definition
		* Range of potential future work
			* Research
			* Analysis
			* Design
			* Development
	* Product roadmap: Problems that need to be solved
		* UX
		* Marketing
		* Content
		* Design
		* Research
		* ...
	* Field roadmaps
		* Problems to be solved by UX
	* Specialty roadmap: Subset of field roadmaps
		* Focus on one area, for instance research

## Product Roadmaps
* Include Product, UX, and engineering
* Collaboration across departments: Product management, user experience, engineering, content strategy, marketing. It captures a strategic vision across an entire product. 
* The product manager is the owner of the roadmap 
* Domain leads (UX, engineering, marketing) work collaboratively with the PM to define the roadmap
* E.g. an engineering lead contirbutes to feasibility
* E.g. a UX lead helping a product manager prioritizing work when it impacts the user. 
* Shared mental model. If anyone at the organization has an understanding of the vision of the product. 
* Sharing the product roadmap helps breaking down silos. The bigger picture. Seeing how our work relates to the other departments. They include other problems, not just UX. They communicate relationships, dependencies. 
* Challenges: it requires crossfunctional participation. You need others to buy into the product vision that the roadmap establishes. 
* It involves politics. 

## Field roadmap
* Field roadmap: It maps the UX Work, including the research, design and content. 
* Includes problems to be solved by any area. 
* UX Directors: Primary creators / directors of field roadmaps. They participate in the higher level product roadmap. They understand the driving strategy and vision. 
* Program managers can also be the creators of field roadmaps. 
* Benefits
	* Bridging areas
	* Field roadmap: Interweaves objectives from different areas. 
	* Enables awareness. 
	* Fosters crosspollination. 
* Communicates the UX Design process. 
* Field roadmap: Meant to outline the process and not to allocate resources individually (this is the specialty roadmap)
* It requires coordination with the product roadmap. 

## Specialty roadmap: Includes only one UX Area
* Focuses on only one UX Area (User Research, UX Design...)
* Outlines the problems this area solves
* Communicate resource bandwidth and allocation. 
* Specialty roadmap cover topics related to only one UX area. 
* Lead or senior UX practitioners: Outlines the team responsibilities. 
* ResearchOps can help. 
* Can also be an individual roadmap, to communicate the strategic approach of the work. 
* Benefits
	* Communicate bandwidth and allocation
	* Visualizing bandwidth
	* To see which team member tackles which problem 
	* Gives insights into the themes we are responsible for
		* Now, next, future... 
	* Unite and align team members within an area. Brings alignment and awareness of the work done by others. 
	* Collaboration is not required and there is less politics involved than creation of product and UX Roadmaps. 
	* Challenges
		* -   **Limited audience.** Specialty roadmaps are, as their name suggests, specific. Thus, they are relatively few people who find them useful (or care about their existence). Less time and labor should go into creating them, since their use is limited. Try to time-box their creation, spend minimal time making them “pretty”, and prioritize a tool that enables easy revisions.    
	* First question is what is the goal we are trying to achieve. 

# Prioritization methods
## 5 prioritization methods in UX and Product
* 5 methods to prioritize the work 
	* Impact effort
	* RICE
	* MoSCoW
	* Kano Model 
	* Feasibility, Desirability, Viability

Prioritizing: 
* User research questions
* User segments
* Features to ideas

## Impact-effort matrix
* quick wins, big bets, fill-ins, and money pits.
* The resulting matrix captures the relative effort necessary to implement candidate features and their impact on the users. It can be subdivided into four quadrants: 
* 1.  **Quick wins** include low-effort, high-impact items that are worth pursuing. 
2.  **Big bets** include high-effort, high-value items; they should be carefully planned and prototyped, and, if executed, are likely to be differentiators against competitors. 
3.  **Money pit** includes low-impact, high-effort items that are not worth the business investment; there are better places to spend time and resources. 
4.  **Fill-ins** comprise low-effort, low-impact items that may be easy to implement but may not be worth the effort as their value is minimal. 

Comparative matrix: Malleable. 
Replace each axis with other criteria
Use multiple matrices to assess more than two criteria. 

-   **Impact** is the value the item will bring to the end user. The level of impact an item will have on end users depends on the users’ need, their alternatives, and the severity of the [pain point](https://www.nngroup.com/articles/pain-points/) the item solves.
-   **Effort** is the amount of labor and resources required to solve the problem. The more technically complex the item, the higher effort it will require.

A general rule of thumb is that the number of votes per person is half the number of items being prioritized. It’s also possible that certain team members vote on a single dimension, according to their expertise — for example, UX professionals may rank impact, while developers may rank implementation effort.

### 1.D. Best for Quick, Collaborative Prioritization

An impact–effort matrix is best suited for quick, collaborative prioritizations. The method has a few advantages:



*The RICE Method ranks items by multiplying* Reach *(the number of users the item affects) by* Impact *(the result the item has on users) and* Confidence *(how much validation you have for your estimates). This resulting number is divided by* Effort *(the amount of work it will take to implement the item) to obtain an item’s final score.* 


### 3.B. Criteria 

This RICE method is based on scoring each item on 4 different dimensions:

-   **Reach**: the number of users the item affects within a given time period 
-   **Impact**: the value added to users 
-   **Confidence**: how confident you are in your estimates of the other criteria (for example, highly confident if multiple data sources support your evaluation) 
-   **Effort**: the amount of work necessary to implement the item 

### 3.C. Process

Using the RICE method is straightforward. Separate scores are assigned for each criterion, then an overall score is calculated. 

-   A reach score is often estimated by looking at the number of users per time period (e.g., week, year);  ideally, this number is pulled from [digital analytics](https://www.nngroup.com/articles/analytics-user-experience/) or [frequency metrics](https://www.nngroup.com/articles/frequency-recency/). 
-   The impact score should reflect how much the item will increase delight or alleviate friction; it is hard to precisely calculate, and, thus, it’s usually assigned a score (for example, through voting, like in the previous methods) often on a scale from .25 (low) to 3 (high).  
-   The confidence score is a percentage that represents how much you and your team trust the reach and impact scores.  100% represents high confidence, while 25% represents wild guesses. 
-   The effort score is calculated as “person-months” — the amount of time it will take all team members to complete the item. For example, an item is 6 person-months if it would require 3 months of work from a designer and 1 month from 3 separate developers.  






## 4\. MoSCoW Analysis

### 4.A. Overview

MoSCoW analysis is a method for clustering items into four primary groups: *Must* *Have*, *Should* *Have*, *Could* *Have*, and *Will* *Not* *Have*. It was created by Dai Clegg and is used in many Agile frameworks. 

![MoSCoW uses 4 categories (Must Have, Should Have, Could Have, and Will Not Have) to group and prioritize items.](https://media.nngroup.com/media/editor/2021/11/16/moscow-nng.png)

*MoSCoW analysis groups items into four groups:* Must have *(items that are essential to the project),* Should have *(items that are very important, but not essential),* Could have *(items that are nice to have), and* Will not have *(items that aren’t needed).* 

### 4.B. Criteria

This prioritization approach groups items into four buckets: 

-   **Must have**: items that are vital to the product or project. Think of these as required for anything else to happen. If these items aren’t delivered, there is no point in delivering the solution at all. Without them the product won’t work, a law will be broken, or the project becomes useless. 
-   **Should have:** items that are important to the project or context, but not absolutely mandatory. These items support core functionality (that will be painful to leave out), but the project or product will still work without them. 
-   **Could haves**: items that are not essential, but wanted and nice to have. They have a small impact if left out. 
-   **Will not have:** items that are not needed. They don’t present enough value and can be deprioritized or dropped. 

### 4.C. Process

MoSCoW analysis can be applied to an entire project (start to finish) or to a project increment (a sprint or specific time horizon). 

Begin by identifying the scope you are prioritizing items for. If your goal is to create a UX roadmap, you’ll usually have to prioritize for the first three time horizons: now (work occurring in the next 2 months), next (work occurring in the next 6 months), and future (work occurring in the next year). 

Compile the items being prioritized and give each team member 3 weighted voting dots, (one dot with a 1 on it, the next with a 2 on it, and so forth). Ask team members to assign their dots to the items they believe most important, with 3 being weighed most heavily.

![Each team member places weighted votes, resulting in scores for each item.](https://media.nngroup.com/media/editor/2021/10/29/moscow-voting.png)

*Team members vote on the items that they believe are* Must Have *for the roadmap time horizon. In the example above, each team member is given three voting dots, one with a 1, one with a 2, and one with a 3. They place their dots on the three items they believe should have the highest priority (with 3 being the item of highest priority among the 3).* 

Add up each item’s score based on the ranked votes (3 = 3 points and so forth). Identify the items with the highest scores and make sure that everybody in the group agrees on their importance. 

As each item is discussed and agreed upon as a *Must* *Have*, move it to a new dedicated space. Repeat this process for lower-priority items and assign them to the *Should* *Have,* Could *Have*, and *Will* *Not* *Have groups* based on their scores.

Once you have assigned each item to one of the four groups, establish the resources and bandwidth required for each group, starting with the *Must* *Haves*. Keep track of the total bandwidth and resources at your disposal, distributing and allocating your total amount across *Must* *Haves* (which should get the most resources), *Should* *Haves* (with the second most resources), and finally *Could* *Haves* (with few resources)

4.D. Best for Teams with Clear Time Boxes

MoSCoW is a good prioritization method for teams looking for a simplified approach (given the relatively vague prioritization criteria set) and with a clear time box identified for the work.

The Kano model scores items based on satisfaction and functionality. Using these scores, items can be clustered into 4 groups:* Attractive*,* Performance*,* Indifferent*, and* Must be*.* 

### 5.B. Criteria 

This prioritization method uses two primary criterions to rank items: functionality and satisfaction. 

-   **Functionality** represents the degree to which the item can be implemented by the company. It can have 5 possible values ranging from -2 to 2:
    -   **None (-2)**: the solution cannot be implemented
    -   **Some (-1)**: the solution can be partly implemented
    -   **Basic (0)**: the solution’s primary functions can be implemented, but nothing more 
    -   **Good (1)**: the solution can be implemented to an acceptable degree
    -   **Best (2)**: the solution can be implemented to its full potential 
-   **Customer satisfaction** for each item is also assessed on a spectrum from -2 to 2:
    -   **Frustrated (-2)**: the solution causes additional hardship for the user
    -   **Dissatisfied (-1)**: the solution does not meet users’ expectations
    -   **Neutral (0)** 
    -   **Satisfied (1)**: the solution meets users’ expectations
    -   **Delighted (2)**: the solution exceeds users’ expectations

### 5.C. Process

Each item is first assigned a satisfaction score and a functionality score. The satisfaction score should be based on user data — for example, on existing user research or on a top-task user survey asking users to rate the importance of each feature; the functionality score can be rooted in the collective expertise of the team.  

These scores are then used to plot items onto a 2D-graph, with the x-axis corresponding to functionality and the y-axis to satisfaction. Each axis goes from -2 to 2. 

Based on their placement on their scores, items fall into one of four categories: 

1.  The **Attractive** category (often called *Excitement*) are items that are likely to bring a considerable increase in user delight. A characteristic of this category is the disproportionate increase in satisfaction to functionality. Your users may not even notice their absence (because they weren’t expectations in the first place), but with good-enough implementation, user excitement can grow exponentially. The items in the *Attractive* are those with a satisfaction score of 0 or better. These items appear above the blue *Attractive* line in the Kano illustration above.
2.  The **Performance** category contains items that are utilitarian. Unlike other categories, this group grows proportionately. The more you invest in items within this category, the more customer satisfaction they are likely to prompt. The items in the *Performance* category have equal satisfaction and performance scores and fall on the green line in the Kano illustration above.  
3.  The **Indifferent** category contains items that users feel neutral towards — satisfaction does not significantly increase or decrease with their functionality and is always 0. Regardless of the amount of investment put into these items, users won’t care. These items are all placed on the dark blue *Indifference* line (which overlaps with the x-axis). 
4.  The **Must-be** category are basic items that are expected by users. Users assume these capabilities exist. They are unlikely to make customers *more* satisfied, but without them, customers will be disproportionately dissatisfied. Items fall into the Must-be category when their satisfaction score is 0 or worse. These are the items in the purple area of the Kano diagram, below the purple *Must Be* line.

Once items are assigned to groups, make sure that everybody in the team agrees with the assignment. Items with scores of (0,0), (-2,0) and (+2,0) may initially belong to two groups. In these cases, discuss the item and ask yourself if user value will grow proportionately with your team’s investment. If the answer is yes, group the item with *Performance*. In cases this is false, group the item with *Indifferent*. 

Move items as needed, then prioritize items into your roadmap. Items in the *Performance* category should have the highest priority, followed by *Must* *be*, *Attractive*, then *Indifferent*. 

Feasibility, Desirability, and Viability Scorecard 

### 2.A. Overview

This method was developed by IDEO in the early 2000s. It ranks items based on a sum of individual scores across three criteria: feasibility, desirability, and viability. 

![A table with items in each row and the criteria in each column. Totals are calculated for each item.](https://media.nngroup.com/media/editor/2021/10/29/feasibility-desirability-viability-scorecard.png)

*Create a table where items’ individual scores can be documented and added for a total score. Total scores are then compared, discussed, and reorganized to determine the final prioritization. The items with the highest overall scores best satisfy the prioritization criteria (in this case, desirability, feasibility, and viability).* 


### 2.B. Criteria 

This prioritization method uses three criteria to rank items (i.e., features to be implemented):

-   **Feasibility**: the degree to which the item can be technically built. Does the skillset and expertise exist to create this solution?
-   **Desirability**: how much users want the item. What unique value proposition does it provide? Is the solution fundamentally needed, or are users otherwise able to accomplish their goals? 
-   **Viability**: if the item is functionally attainable for the business.  Does pursuing the item benefit the business? What are the costs to the business and is the solution sustainable over time? 

### 2.C. Process

Create a table, with one row for each possible item, and columns for the 3 criteria — feasibility, desirability, and viability. Then, determine a numeric scoring scale for each criterion. In the example above, we used a numeric scale from 1 to 10, with 1 being a low score. 

Next, give each item a score across each criterion. Scoring should be as informed as possible — aim to include team members who have complementary expertise. Once each item is scored across each criterion, calculate its total score and force a rank. Sort the table from highest to lowest total score, then discuss the results with your team. 


D. Best for Customized Criteria 

This scorecard format is highly customizable. You can add columns to reflect criteria specific to your organization’s context and goals. You can also replace the criteria with others relevant to you. For example, the [NUF Test](https://gamestorming.com/nuf-test/), created by Dave Gray, uses the same scorecard format, but with *New*, *Useful*, *Feasible* as the criteria set. 

# Roadmap

*The 6 steps to roadmapping*

A [UX roadmap](https://www.nngroup.com/articles/ux-roadmaps/) is a strategic, living artifact that aligns, prioritizes, and communicates a UX team’s future work and the problems it needs to solve. Roadmaps are successful when they make realistic promises, value functionality over pretty visuals, or are strategic documents instead of feature-specific release plans. 

## The 6 Steps of Roadmapping

Successful roadmapping include 6 key high-level steps:

1.  **Establish goals:** Determine the purpose of your roadmap and who should be involved.
2.  **Gather inputs:** Collect problems that need to be solved from stakeholders and existing research.
3.  **Create themes:**  Cluster problems into into themes. 
4.  **Prioritize themes:** Establish criteria and create a scoring framework to rank themes.
5.  **Visualize and share:** Plot themes into a timeline and distribute the resulting visualization (your roadmap).
6.  **Revisit and update:** Routinely return to your roadmap and make adjustments as necessary. 

### **1A. Why: Determine Your Objective** 

The first question to ask is:  What is the primary purpose of this roadmap? A roadmap can have different goals:  

-   Increase team awareness
-   Enable crossdisciplinary visibility and alignment 
-   Educate others on the UX process 
-   Manage bandwidth and resource allocation  
-   Show to stakeholders what problems you aim to solve
-   Prioritize future work 
-   Define a UX vision 
-   Identify a [minimum viable product (MVP)](https://en.wikipedia.org/wiki/Minimum_viable_product) 

Roadmaps can become political, complex artifacts. A single, primary purpose for your roadmapping initiative will keep it focused and will establish clear priorities (for example, what information to communicate, who is involved in the process, or the tool the roadmap lives in). 

### **1B. What: Identify a Scope**

Determine the [scope of your roadmap](https://www.nngroup.com/articles/roadmap-types/). Roadmaps that include UX work can have 3 scopes: product, discipline, and specialty. Identify which scope is best for your objective. If you will create a discipline or specialty roadmap, clearly establish what product(s) the roadmap will serve. Both these types of roadmaps roadmaps can visualize work across several products within a portfolio (the broadest approach) or across just one specific product-area within a single product (the lowest-granularity approach). 


### 1C. Who: Establish a Core Team
* Pull a cross-disciplinary team together. 
* Establish stakeholder support

### Gather Inputs
* Gather existing artifacts related to the scope of the roadmap. 
	* Previous roadmaps
	* Product Roadmaps
	* Journey Maps
	* Service Blueprints
	* Leadership Strategy
	* Backlog (in design or development)
* Collect any available data related to the roadmap scope
	* Qualitative or quantitative user research
	* Customer or employee support logs
	* Market research surveys
	* Voice of Customer Studies
* If unhelpful or untrustworthy data: perform stakeholders interviews to fill in the gaps

### Create themes
* Create themes like in user research.

### List candidate problems to solve
![Gather inputs from across sources and combine them into a single list of problems to solve.](https://media.nngroup.com/media/editor/2020/10/29/screen-shot-2020-10-29-at-13626-pm.png)

* Comb through everything and come up with an inventory of potential problems. 
* Condense all possible issues into a single space where they can be grouped. 

### Assess Patterns
* Sort candidate problems to be solved into clusters, using affinity diagrams.

![Assess patterns across inputs and form them into themes of high-level problems to solve](https://media.nngroup.com/media/editor/2020/10/28/ux-roadmaps-grouping-into-similarities.png)

### Organize and label
* Organize and label each cluster into a polished theme

1.  **Beneficiary:** The recipient(s) of the UX work (e.g., end users, fellow employees, or even internal stakeholders)
2.  **Need:** The problem that will be solved (the purpose of the UX work)
3.  **Business objective(s):** Objectives and potential outcomes (from a business point of view) that will be achieved upon completion (e.g., new market insight, user growth, increased engagement, ease of discovery, revenue)

### Prioritize then themes
Use established methods to prioritize and determine which themes have the highest importance
-   RICE (Reach, Impact, Confidence, Effort) scoring model 
-   Critical path (prioritizing tasks within a primary flow)
-   Kano model (rank items against user’s perceived value)
-   ROI scorecard (prioritize based on return on investment)
-   MoSCoW (Must have, Should have, Could have, and Will not have) scoring scheme

### Establish criteria to prioritize 
* Aim for 4-8 factors
* As a starting point: pick 2 user oriented factors and 2 business-oriented factors. 
	* **User-Oriented Examples (Pick 2)** 
	* **Business-Oriented Examples (Pick 2)** 
	* Impact to the user(s)
	* Alignment with company strategy 
	* % of users impacted
	* Market differentiation 
	* Severity (of pain or friction)
	* ROI (return on investment) 
	* Alternative solutions available 
	* Effort (time + cost estimate)
### Calculate and rank
* Give each theme a score based on the criteria
* Force a rank
* Plot the themes to the closest time horizon (now, next). Themes with lowest score would be assigned to later time horizons (future or guture ++)
* Are there any gaps in understanding?
* For high level roadmaps meant for stakeholder and other teams: high fidelity needed. 
* Create a concise and clear visual that has context, date and a version number. 
* Ask for feedback and consider what kind of feedback you want. 
* Roadmaps: Move finished themes from now to complete
* Always start small

# UX Roadmaps definition and components

* Roadmap: Prioritizes and communicates UX Team future work and problems to solve

∑

![Example UX Roadmap](https://media.nngroup.com/media/editor/2020/06/09/screen-shot-2020-06-09-at-120635-pm.png)

## Roadmap structure and primary components

* Can take several forms
	* Organized lists
	* Spreadsheets
	* Slide decks
	* High fidelity visualizations
	* Sticky-note walls
	* Mix of media*

**Context dimension: **
* Framing the meaning and use of the roadmap to be used by anyone who reads it
* Scope: Owner, purpose and several components
	* Title: Product or portfolio team for the roadmap
	* Mention the high-level goals
	* Date: When the roadmap was created or last updated
	* High-level goals: Broad company or organization strategy that the roadmap works towards
	* Time: Providing the roadmap with timeframe and includes 3 horizons
		* Now: UX Work in progress, completed in the immediate future
		* Next: Near-future work
		* Work: UX Work that is 6 or more months away
		* Theme: Future UX Work, including areas of focus, initiatives, or problems to be solved and plugged in a corresponding time horizon. 

![](https://media.nngroup.com/media/editor/2020/06/09/screen-shot-2020-06-09-at-122727-pm.png)

**Themes**
* Themes are high-level bundles of work and should include 3 components:


![Themes are comprised of 3 things: a beneficiary and need, the business outcome, and the team that will solve the problem. ](https://media.nngroup.com/media/editor/2020/06/11/screen-shot-2020-06-11-at-104711-am.png)


1. Beneficiary and need: End users, internal stakeholders. 
2. Need: Problem to be solved (purpose of UX Work)
3. Business Objectives (Objectives to be achieved from a business point of view : e.g., new market insight, user growth, increased engagement, ease of discovery, revenue, etc.)
4. Success Metrics
5. Ownership
	1. Person who completes the work
	2. What: Kind of work that needs to be done
6. ***Completed* and *Future*++** are two additional time horizons (think pre and post roadmap scope). 
	1. Completed: UX Work that was just delivered
	2. Future++ UX Work that can be potentially placed in the future column. 
7. **Product areas**
	1. Area of the product the UX work will touch. 
	2. Many different components and touchpoints. 
	3. The naming should align the language of the audience using the roadmap. (e.g.,[touchpoints](https://www.nngroup.com/articles/channels-devices-touchpoints/)).
8. **Subthemes**
	1. Multiple subgoals the theme encompasses. 
	2. Specific user segment or persona
	3. Solutions from past work
	4. Discrete features tested and validated. 
	5. Subethemes included within themes in the now column
9. Confidence estimates:
	1. Informal assessments of likely impact and demonstrated need for the different themes. 
	2. Low confidence estimates: Attached to items based on assumptions or open questions
	3. High condidence estimates: Assigned to work validated by research or data. 
	4. Grading scale:
		1. High confidence would get a 6/7
		2. If item is epxloratory, lacking previous research, assign it a low/moderate score of 4/7
	5. Allows to understand what items are built on previous work, what items are a bigger bet. 
	6. Disclaimer: requirements or risks associated with a theme or a component in the roadmap. 

## Adaptations
	1. Roadmap should be adjusted based on how the roadmap will be used and by whom
	2. Scope
		1. Roadmap can be narow or broad. 
			1. Narrow: Singular initiative. 
			2. Broad: Portfolio-wideUX redesign. 
	3. Lens
		1. Roadmaps can be done by expertise or by product team. 
			1. Through the lens of a specific product and including work across expertise (research, content strategy, design...)
			2. Roadmap for a group of researchers serving multiple teams. 

## Roadmaps vs other tools

### Roadmaps vs release plans
* What should we solve for? : Roadmap
* How should we solve it? Release plan

### Roadmaps vs Kanban boards
* They differ in granularity and purpose. 
* Roadmap items: High level problems to be solved. 
* Establishing the product vision. 
* Roadmaps: Lack formal, discrete task definition. Represent a range of potential future work. (from research, to analysis, to design and development) that has yet to be defined.
* Roadmap: Product. Project: Kanban. 


### Roadmaps vs Product Backlogs
* An effective product backlog breaks down a roadmap’s high-level vision into actionable items that the development team can accomplish. 

## Successful roadmaps
* Based on user research 
	* Themes as user problems to solve
	* Items plugged into a UX roadmap should be derived from a mix of qualitative and quantitative research
	* Themes in the roadmap should be driven by research. 
	* Roadmap should specify future research that needs to be done*
	* prioritise outcome over output. We should map out the higher levels initiatives instead. 
	* Contextually appropriate
		* Roadmaps should be rooted in the organization's larger strategy. 
	* Roadmaps are prototypes for strategy over time. 
	* Build roadmap with input from others to increase buy-in and support. 


![](https://media.nngroup.com/media/editor/2020/06/11/screen-shot-2020-06-11-at-104804-am.png)



## UX Roadmaps: Who, When and How Much Time?


Roadmap: Bridge between the company's UX Vision and Project Tracking Artifacts
![Needs or problems to solve are represented on a roadmap, whereas solutions to those needs are represented on a project plan](https://media.nngroup.com/media/editor/2022/05/07/roadmaps-v-project-plans.png)
- Roadmap should not explain how the work should be done. 
- They capture a range of potential problems to be solved. 

### Types of product roadmaps which can be created

1.  **Product roadmaps** represent all future problems that need to be solved, including ones related to UX, marketing, content, design, research, development, support, or operations. 
2.  **Field roadmaps** represent all future problems to be solved by UX (for example, related to design, research, or content), but do not include problems outside of UX (for example, in marketing, development, and support — these fields might obviously have their own, separate, field roadmaps).
3.  **Specialty roadmaps** are a subset of field roadmaps and focus only on problems within one UX area (for example, in user research). 

![3 Types of Roadmaps: Product, Field, and Specialty ](https://media.nngroup.com/media/editor/2020/10/19/3-types-of-roadmaps.png)


![3 Types of Roadmaps: Product, Field, and Specialty ](https://media.nngroup.com/media/editor/2020/10/19/3-types-of-roadmaps-vertical.png)

![A product roadmap is the broadest of the 3 types and drives other roadmaps. ](https://media.nngroup.com/media/editor/2020/10/19/nng-product-roadmap.png)



![Field roadmaps map UX work, including research, design, and content. ](https://media.nngroup.com/media/editor/2020/10/19/nng-field-roadmap.png)


![Specialty roadmaps map a specific UX area. ](https://media.nngroup.com/media/editor/2020/10/19/nng-specialty-roadmap.png)

## Using Prioritization Matrices to Inform UX Decisions


### Prioritization Matrices
A prioritization matrix serves to identify the most important problems. This structured, objective approach helps achieve collaborative consensus while satisfying the varied needs of the user and business.


![Basic Prioritization Matrix ](https://media.nngroup.com/media/editor/2018/05/21/screen-shot-2018-05-21-at-101407-am.png)

### **1\. Establish the items, criteria, and scale you will use**

There are three initial steps to creating a prioritization chart. First, establish the items you are prioritizing and write them on individual sticky notes. These can be:

-   Projects 
-   Ideas 
-   Features that you plan to implement 
-   [Jobs to be done](https://www.nngroup.com/articles/personas-jobs-be-done/)
-   User groups or [personas](https://www.nngroup.com/articles/persona/)
-   Research activities

Next, you’ll define the criteria according to which you’ll perform the prioritization.  For prioritizing different ideas, the criteria could be impact on the user or feasibility. For prioritizing personas, they could be percentage of user base and ROI. Regardless of what items you are prioritizing, the criteria should always be derived from the overall goals of the project and business needs.

Once you have the items and criteria, develop the scale. The scale can be as simple as high or low (if your criteria are feasibility’ or impact on the user, for example). Or, it could be made of actual numbers (if you were plotting the percentage of users, the scale could range from 0 to 100).

### **2\. Individually vote based on expertise**

Disperse different colored dots to each team member. A general rule of thumb is the number of votes per person is half the number of items being prioritized. While each team member gets the same number of votes, they should vote based only on criteria that fall within their domain of expertise. Use different colors for different areas of expertise. For example, on a matrix plotting feasibility vs. impact on the user, developers may have green dots and rank feasibility, while designers may have orange dots that represent impact on the user.

Team members then silently vote on items. Members are allowed to place multiple votes on one item. These votes should be educated opinions, so time to research or investigate prior to voting may be needed.

### **3\. Draw a chart and use votes as a basis for placing items**

Using the team’s votes as a guideline, collaboratively place each item onto your chart. There should be little discussion in this step. The goal is only to get the items up onto the plot based on the votes placed in the prior step.

![Example prioritization matrix after votes have been placed](https://media.nngroup.com/media/editor/2018/05/21/screen-shot-2018-05-21-at-102112-am.png)

*An example matrix after items have been placed based on votes*

### **4. Discuss and negotiate placement**

Once everything is placed onto the chart, it’s time to discuss the results and compare where items fell. Some questions to ask the team may include:

-   Are the items that received equal votes really equal? Is idea A equally feasible to idea B even though they received the same number of votes? Why or why not?
-   Do we agree with the items that ended up at the ends of the scales?
-   Why did certain items receive no votes? Was it that we didn’t have enough votes, or do they truly provide no value based on our criteria?

Throughout discussion, the team should feel free to collaboratively move items. At the end, there should be agreement on the final placement of all the items.

### **Increase the number of criteria.**

One can use an arbitrary number of criteria, though visualization becomes difficult with 3 criteria and extremely hard with 4 or more. Thus, if possible, we like to stick to 2 criteria.

### **Create multiple plots to compare across criteria.**

When there are more than two criteria that influence decision making, you can plot items across multiple graphs. Doing so allows the team to access multiple variables that may be important to users or to the business. For example, an idea may rank high in impact on the user and feasibility, but have very little effect on ROI.

When setting up multiple matrices, always place the best outcome on the far right or top left of your axis. This allows you to easily compare several matrices and identify the best items as those that consistently fall in the top right of your matrix.

![Two comparable prioritization matrix](https://media.nngroup.com/media/editor/2018/05/21/screen-shot-2018-05-21-at-102530-am.png)

Two comparable matrices help visualize items that meet multiple business requirements (in other words, that fall consistently in the ‘yes’ quadrant).

### **Incorporate a more rigorous scale.**

The above examples employ a simple, binary scale; however, you can use continuous scales when appropriate. For example, rather than just using a high–low scale for feasibility, you could use the estimated time for implementing a feature (e.g., 1 year vs. 2 weeks). Resources could be ranked according to a quarterly budget: $50,000 vs. $1,000.
