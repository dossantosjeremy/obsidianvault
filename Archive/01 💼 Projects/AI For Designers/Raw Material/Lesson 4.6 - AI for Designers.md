---
category: "[[Clippings]]"
author: "[[The Interaction Design Foundation]]"
title: "Lesson 4.6 - AI for Designers"
source: https://www.interaction-design.org/courses/ai-for-designers/lessons/4.6
clipped: 2024-05-09
published: 
topics: 
tags: [clippings]
---

Estimated time to complete: 36 mins

![An AI-generated image of a woman with large white wings, pale robes and a crown sitting at a desk working on a laptop.](https://public-images.interaction-design.org/courses/lesson-materials/04-06-00-hero-image.jpg)

*An established set of patterns help designers create more intuitive experiences. However, what if the technology is so new that there aren’t any “universal” patterns? As AI gains more steam and more product designers incorporate the technology in applications, companies such as Google, IBM and Microsoft have developed their own set of design patterns.* 

In this video, AI Product Designer Ioana Teleanu takes a closer look at some of these patterns.

**

Show Hide video transcript

1.  00:00:00 --> 00:00:33
    
    AI is a very dynamic field. There  are new types of interaction challenges and   questions popping up with every new product or use case, but some overarching themes and general   interaction problems have emerged. From my own experience designing AI-powered products as well as analyzing dozens of products based on AI, I've noticed there are a couple of interaction pattern categories starting to be established.
    
2.  00:00:33 --> 00:01:01
    
    The first one is calling AI, or summoning it, accessing it, which is essentially a way of providing the user  with enough freedom and control to decide when to   enhance their work with AI how is AI brought  up in the product then there's a category of   mutual learning educating on what the system can  do and can't do and how to make the most out of   it capturing feedback to learn from the users  and so on another category is building trust  
    
3.  00:01:01 --> 00:01:38
    
    AI systems are unpredictable sometimes unreliable  sometimes inaccurate how do we create systems that   are transparent and speak to these risks and  the associated fears people have around them   then there's a big category of content generation  editing and augmentation essentially creating an   editing work with the help of AI and then finally  error handling and prevention accountability   things such as admitting when you're wrong  giving users a sense of control and a way out   so so let's dive into these for once users need  a way to access Ai and one thing to consider is  
    
4.  00:01:38 --> 00:02:00
    
    that maybe users don't want to use AI all the  time so you don't want to be loud or annoying   with how you present it plus you'll want to avoid  interjecting and interrupting them when they're   in the middle of focused work how can we provide  controls that let them decide when they want to   sit back and let AI do its thing and when they'd  rather take the wheel themselves some ways of  
    
5.  00:02:00 --> 00:02:33
    
    calling or better said summoning AI are specific  interface actions highlighting text right click   persistent buttons from where you can access AI  capabilities always visible on screen side panels   AI drawers contextual popups and suggestions  summoning spells things such as shortcuts or   special keys voice hey AI do this for me most  of them stem from traditional interface design   but the challenge here is under understanding  what are the right moments in which the user  
    
6.  00:02:33 --> 00:03:00
    
    might need and be open to using AI augmentation  in their work a similar problem is educating   them in machine learning applications both the  user and the system are learning being trained   by each other and adapting to each other's needs  and contexts there's a mutual learning that goes   on or should go on as we're perpetually teaching  the user what we can can't do and how how to best  
    
7.  00:03:00 --> 00:03:33
    
    achieve their goals while we're learning from  their usage patterns actions feedback and more   it's a beautiful learning Loop some patterns  for Education are prompt templating custom   instructions meaning persistent context tutorials  generative Wizards so interactive guides generated   by AI capturing feedback from the user another  category of patterns is in the space of building   trust we've explored what makes trusting AI  systems so difficult data privacy concerns  
    
8.  00:03:33 --> 00:04:05
    
    a lack of understanding of how they work media  coverage of bad examples and so on but how can we   address these in design borrowing from Microsoft's  principles for AI design there are two main rules   make clear what the system can do and make clear  how well the system can do what it can do you can   explore things such as an introduction of what on  what the system can do and how well Google offers   a template that suggests a structure for this  message and it goes like this this is your product  
    
9.  00:04:05 --> 00:04:36
    
    or feature and it will help you buy listing the  core benefits right now it's not able to primary   limitations of AI over time it will change to  become more relevant to you you can help it get   better by user actions to teach the system other  methods for building trust and transparency are   showing confidence scores sending the user low  performance alerts when things don't go well add   asking the user for consent showing disclaimers  showing demonstrated thinking explanations of  
    
10.  00:04:36 --> 00:05:03
    
    the algorithm so essentially making clear why the  system did what it did another large category of   patterns is generating the main application of AI  in our work right now it's through its generative   nature generating content ideas refining editing  them augmenting our own writing and thinking and   so on there are two main patterns emerging ing  for how generative AI is being presented to the  
    
11.  00:05:03 --> 00:05:30
    
    user contextual suggestions things such as small  models or signifiers elements that appear close   to where you're working and conversational  spaces mostly in the form of side panels that   are augmenting neighboring your work or full  playgrounds like in the case of chat GPT what   AI does through these patterns is essentially  augment your work with things such as grammar  
    
12.  00:05:30 --> 00:06:03
    
    correction suggested continuations predictive  text you can think about Gmail add more of or   continue with which essentially means creating  similar assets many companies are adding AI   capabilities to their products and even though  the patterns for generative AI are very much   subject to experimentation right now I think  we will see the industry converge towards some   generally accepted standard that we will all be  able to leverage in the way we add generative  
    
13.  00:06:03 --> 00:06:31
    
    AI in our design the last category I'm seeing  emerge is error handling and prevention things   such as admitting when you're wrong apologies  for inaccuracy providing ways out things such   as stop generating supporting effective dismissal  undo automated actions correcting classification   errors and many more these are the main patterns  I've personally broke into mental categories but  
    
14.  00:06:31 --> 00:07:03
    
    there's important and much better documented  work being done in the space by companies such   as Microsoft Google IBM and I want to encourage  you to check their AI pattern libraries and the   principles that they articulating for AI design  it's critical for us to put thought into these   as they're basically shaping the future of  products and we have the opportunity to set   a strong healthy Foundation from early  on industry conversations and individual  
    
15.  00:07:03 --> 00:07:14
    
    responsibility should combine to create more  responsible sustainable products in the age of AI
    

**

## Microsoft’s HAX Design Library

Microsoft has developed a comprehensive toolkit for Human-AI Interaction (HAX) that includes guidelines, patterns and examples. Here’s a summary of the guidelines

### 1\. Make Clear What the System Can Do

To help the user understand the application, clearly communicate what the AI can do. This helps set expectations. It can be as simple as one line next to a product feature or when the user first interacts with the feature. Aim to make it visible, yet subtle.

![A screenshot from ChatGPT, both the mobile and desktop versions. The screenshots show the suggestions ChatGPT has when starting a new chat.](https://public-images.interaction-design.org/courses/lesson-materials/04-06-01-chatgpt.jpg)

ChatGPT shows suggested prompts to help the user get started, subtly clarifying what the system can do.

© OpenAI, Fair Use

### 2\. Make Clear How Well the System Can Do What It Can Do

Set realistic expectations for how well the system can function. Clear expectations will help build trust. If you set an extremely high bar, users will be disappointed. For example ChatGPT, the generative chatbot, mentions that its answer may be outdated, when relevant.

![A screenshot from a ChatGPT chat. In the screenshot the ChatGPT response has been underlined where the AI tool's response has demonstrated its limitations. For instance it says "As of my last knowledge update in January 2022..."](https://public-images.interaction-design.org/courses/lesson-materials/04-06-02-chatgpt.jpg)

When asked “What does Siri sound like?” ChatGPT begins the response with a disclaimer, “As of my last knowledge update in January 2022” to indicate the system’s limitations—that the information could potentially be outdated. It reiterates this message towards the end and offers a way to verify its answer, saying, “I would recommend checking Apple’s official website or your device's settings.”

© OpenAI, Fair Use

### 3\. Time Services Based on Context

If your application proactively initiates interactions with users, consider the appropriate timing of the notification based on the user’s context. For example, if the user is driving or likely to be busy (say, in a meeting or at the dentist’s clinic), consider if the AI should still send push notifications, or postpone it.

### 4\. Show Contextually Relevant Information

Display information that is relevant to the user’s context.

![A screenshot of a Google's search results after 'movies day' was searched. It shows movie posters, their titles and their show times.](https://public-images.interaction-design.org/courses/lesson-materials/04-06-03-movies-today.jpg)

Google’s search results page offers contextual information. For example, when you search for a movie, the page will display the show times, a search for a flight will return timings and a search for a product will return shopping results at the top of the page.

© Google, Fair Use

### 5\. Match Relevant Social Norms

Consider the users’ cultural and social context and deliver content that’s appropriate for them. For example, some cultures are more formal than others, so the language and tone of the messages must match the norms.

### 6\. Mitigate Social Biases

Ensure your technology doesn’t amplify stereotypical notions. For example, many voice assistants have feminine names and feature a female voice which reinforces the sexist viewpoint of assistants always being female.

An animated gif showing the Apple digital assistant, Siri. Next to the animated Siri icon is an iPhone showing the different options for the application.

After years of using a female Western voice, Apple switched to a more inclusive range of voices in both male and female versions that users can choose from.

© Apple, Fair Use

### 7\. Support Efficient Invocation

Allow the user to call the AI services manually.

An animated gif from the tool, Notion AI's, desktop application. The title of the note is 'Vacation To-Do List' and it's prompted to write the list. The list is then generated by the tool.

Notion’s AI is non-intrusive and the interface has clear instructions on how to invoke it—a space bar.

© Notion, Fair Use

### 8\. Support Efficient Dismissal

Just as you make it easy to summon AI, enable users to easily dismiss AI suggestions.

![A screenshot from the Instagram mobile app. On the screen is the alert from when you interact with an add and then get the option to hide, report or learn more about Instagram ads.](https://public-images.interaction-design.org/courses/lesson-materials/04-06-07-report-ad.jpg)

Instagram offers an easy way to dismiss advertisements.

© Instagram, Fair Use

### 9\. Support Efficient Correction

Provide the user with full control over AI. For example, Google Docs offers predictive text that users can manually approve. In cases where the application automatically changes the text (such as spelling errors), it offers an option to undo the change.

An animated gif of the desktop version of Google docs. It demonstrates the use of AI in generating predictive text.

Google Docs offers users full control over its automated suggestions, either asking the users’ approval (the predictive text) or providing an option to undo the suggestion (such as the spelling correction).

© Google, Fair Use

### 10\. Scope Services When in Doubt

In cases where the system isn’t sure what the user wants to do, make the system clarify the user’s intent before executing the action. This way, the system will be less error-prone, and can learn from the user’s actions.

A short video clip that shows GitHub's new AI-powered feature. It generates code based on prompts.

GitHub Copilot suggests code snippets based on what the user asks for. In cases where it’s not sure, the AI suggests multiple solutions that the user can choose from.

© GitHub, Fair Use

### 11\. Make Clear Why the System Did What It Did

To foster transparency and to build trust with the users, explain the reason behind the AI features.

![A screenshot of the desktop website of online retailer, Amazon. The product shown is a bag of coffee beans. Underneath the product image and details is a horizontal list of similar recommended products.](https://public-images.interaction-design.org/courses/lesson-materials/04-06-10-amazon-suggestions.jpg)

Amazon explains the rationale behind its product suggestions in the heading, “Customers who viewed items in your browsing history also viewed.” This clarifies how the system works in human-friendly language.

© Amazon, Fair Use

### 12\. Remember Recent Interactions

If you’ve been frustrated by customer-support chatbots asking the same inputs every time you start or pick up a conversation, then you’ve already met this guideline! Keep recent interactions with the user in “short-term” memory to offer a natural, seamless experience. For example, if you pick up a conversation with ChatGPT even a few days later, you don’t have to repeat instructions.

![A screenshot from a ChatGPT chat. In the screenshot the ChatGPT response has been underlined where the AI tool's response has demonstrated its limitations. For instance it says "As of my last knowledge update in January 2022...". Following that is another prompt, which is followed by another response. The second response refers back to the first prompt, which shows the AI tool's ability to remember interactions. ](https://public-images.interaction-design.org/courses/lesson-materials/04-06-11-siri-voice.jpg)

In this interaction with ChatGPT, the user asked, “What about Alexa?” Standalone, this question is vague. However, the AI recalls that the question before was, “What does Siri sound like?” and answers the question accordingly, saying, “Alexa, like Siri, offers multiple voice options…”

© OpenAI, Fair Use

### 13\. Learn from User Behavior

Personalize services based on user behavior and preferences. For example, Grammarly learns the user’s writing profile and personalizes the content according to their voice.

![A screenshot from Grammarly. It shows the user's 'Communicatio. profile' which lists the characteristics of their writing style, their tone, profession and language.](https://public-images.interaction-design.org/courses/lesson-materials/04-06-13-grammarly.jpg)

© **[Grammarly](https://www.grammarly.com/ai)**, Fair Use 

### 14\. Update and Adapt Cautiously

Keep your AI updated with new information to improve the functionality and personalization. Ensure you proceed carefully and base the updates on adequate information so that you do not disrupt the user’s workflow.

### 15\. Encourage Granular Feedback

Seek as much feedback from the user as possible (without distracting or annoying them, of course). These may be subtle buttons flagging inappropriate content, rating it on a scale, liking and disliking. For example, ChatGPT includes options for liking and disliking individual responses. And if you regenerate a response, it asks if the new response is better than the previous one.

![A screenshot from Grammarly that shows an AI suggestion to improve phrasing.](https://public-images.interaction-design.org/courses/lesson-materials/04-06-15-grammarly-feedback.jpg)

Grammarly asks for granular feedback and asks users to tweak the response to their liking.

© Grammarly, Fair Use

### 16\. Convey the Consequences of User Actions

Let the user know how their actions will impact the AI’s behavior. Depending on the context, you may incorporate the messaging before the user takes action, after they’ve taken the action, remind them about the action in the future, or document it in the help section.

![A mobile screen showing an Emergency Access to Medical ID notification.](https://public-images.interaction-design.org/courses/lesson-materials/04-06-16-apple-health.jpg)

Apple Health reminds users to review their information and explains the consequences of setting the information by stating, “your Medical ID can provide first responders with life-saving information.”

© Apple Health, Fair Use

### 17\. Provide Global Controls

Allow the user to customize their AI preferences. Ensure these options are easy to find and not buried under layers of preferences.

### 18\. Notify Users about Changes

When you update the AI model, make sure you communicate with your users so that they can adjust their expectations.

## The Take Away

As AI in product design evolves, companies have started to define common patterns. Here, we looked at five broad categories of patterns:

-   "Calling" or summoning AI: AI might proactively appear in context or users may manually invoke the AI.
    
-   Mutual learning: The user and system learn from each other.
    
-   Building trust: The system is as transparent as possible, helping the user understand the AI’s capabilities and limitations.
    
-   Generating: The system generates content and ideas.
    
-   Error prevention and handling: Acknowledging errors and providing ways to handle them.
    

Many of the patterns are similar to existing heuristics for interface design, adapted for the context of AI. As with any design project, base your interface and AI model decisions on sound research and rigorous testing.

## References and Where to Learn More

Microsoft's **[HAX Toolkit](https://www.microsoft.com/en-us/haxtoolkit/library/)** lays out guidelines for Human-AI Interaction (HAX) and includes patterns and examples to illustrate the guidelines.

Google’s People + AI Guidebook’s **[Mental Models](https://pair.withgoogle.com/chapter/mental-models/)** explores co-learning and how AI and humans can onboard and teach each other.

## Answer Questions to Get Your Certificate

Why is it important to answer these questions?

-   You’ll significantly improve your **ability to remember** what you’ve just learnt
-   You get closer to **your Course Certificate**
-   Get a **distinction on your certificate** when you score 90% and higher
-   Research shows that when you answer questions, you’ll greatly improve your ability to transfer knowledge into new contexts, such as your **current or future workplace**.