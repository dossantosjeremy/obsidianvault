# Video summary
- Companies like Google, IBM and Microsoft have developed their own set of design patterns

## AI Patterns
- Interaction pattern categories that started to be established. 
- Calling AI, summonizing it, which is a way to provide the user with enough freedom and control to decide when to enhance their work with AI. 
- Mutual learning: Educating on what the system can do, cannot do and how to make the most out of it, capturing feedback to learn from the users... 
- Building trust: How to build system that are transparent, accurate and speak to these risks and the associated fear people have around them. 
- Content generation, editing and augmentation, essentially creating and editing work with the help of AI and finally
- Error handling and prevention: Admitting when you are wrong, giving users a sense of control and a way out. 

### Calling AI
- Maybe users do not want to use AI all the time. 
- So, don't be loud or annoying with how you present it. 
- We want to avoid interrupting them when they are in the middle of focused work. 
- Providing them control for them to sit back or to take the wheel themselves. 
- To call AI: 
	- Highlighting text
	- Right click
	- Persistent buttons so that you can access AI capabilities, always visible on screen.
	- Side panels
	- AI drawers
	- Contextual pop ups and suggestions 
	- Shortcuts and special keys
- The challenge is determining when are users open to use AI in their work, at what moment. 

### Education
- Both AI and the user are learning by being trained and adapting to each other's needs. 
- Perpetual learning as we are telling users what they can, cannot do while we are learning from their usage, patterns , actions, feedback and more. 
- Patterns for education
	- Prompt templating
	- Custom instructions
	- Tutorials
	- Generative wizards
	- Capturing feedback from the user

### Building trust
* Data privacy
* Media coverage
* Microsoft principles
	* Make clear what the system can do 
	* Make clear how the system can do what it can do. 
	* 
* Make an introduction on what the system can do and how well it can do it. 
* Google has a template for that. 

![[Pasted image 20240509130642.png]]

* Patterns
	* Showing confidence scores
	* Showing the user low performance alerts 
	* Asking the user for consent
	* Showing disclaimers
	* Showing demonstrated thinking
	* Explanation of the algorithm. 

### Content generation
- Generating content, writing, ideas, refining them... 
- Augmenting our own writing, thinking... 
- Patterns
	- Contextual suggestions such as small modals appearing close to what we are working on
	- Conversational spaces
		- Side panels
		- Neighbouring the work
		- Full playground with chat gpt
- It augments the work with 
	- Grammar correction
	- Suggested continuations
	- Predictive text
	- Add more of or continue with, which means creating similar assets

### Error handling or prevention
* Apologies for inaccuracy
* Stop generating
* automated actions undo
* Classifications error correction

# Microsoft AI Guidelines

* Comprehensive toolkit for human - AI interaction 
* Guidelines, patterns and examples

## Make clear what the system can do
* One line next to a product feature
* When the user first interacts with the feature
* Make it visible but subtle
* Clearly communicate what the AI can do.

![[Pasted image 20240510163538.png]]
## Make clear how well the system can do what it can do
- Set realistic expectations. 
- Answers from Chat GPT saying it may be outdated, when this is relevant

## Time services based on context
- Consider the appropriate timing for notifications to the user based on their context. 
- E.g. postpone notifications if the user is busy (driving, at the dentist...)

## Show contextual relevant information
E.g. results from Google for movies, search for a flight...

## Match the relevant social norms
E.g. some cultures are more formal than others. 

## Mitigate social bias
E.g. female voices for asistants. 

## Support efficient invocation
Allow the user to call the AI services manually
E.g. Notion's AI is non-intrusive and the interface has clear instructions to invoke it. 

## Support efficient dismissal
- Enable users to easily dismiss AI suggestions. 
- \E.g. Instagram offering a way to dismiss advertisements

## Support efficient correction
- E.g. if the AI is wrong or not exactly adapted to user's needs, offer the option to the user to undo the suggestions. 
- E.g. with Google Docs.

## Scope services when in doubt
- When in doubt about the users' needs, make the system clarify it before executing the action. 
- The system is then less error prone and can learn from the users actions
- E.g. GitHub co-pilot. 

## Make clear why the system did what it did
- Explain the reasons behind the AI features to build trust with users. 
- Example from Amazon: Customers who viewed items in your browsing history also viewed... 

## Remember recent interactions
- Keep recent interactions with the user in the short term memory to offer a natural and seamless experience. 

## Learn from user behavior
- Personnalize services based on the user behavior and preferences. 
- Grammarly learns users' writing profile and personalizes the content 

## Update and adapt cautiously

- Keep AI updated with new information to improve functionality and personalization. 

## Encourage granular feedback
- Seek as much feedback from the user as possible. 
- Without distracting or annoying them
- Examples
	- Flagging inappropriate content
	- Rating on a scale
	- Liking and disliking
	- Ask if the response is better than the previous response. 

## Convey the consequences of user actions
- Let the users know how their actions will impact the AI behavior. 
- Depending on the context, include the messaging
	- Before the user takes action
	- After they take action
	- Remind them of the action in the future
	- Document the action in the help section

## Provide global controls
* Allow users to customize their AI preferences. 
* Ensure these options are easy to find and not burried

## Notify users about changes
- When updating the AI model, make sure we communicate with users so that they adjust their expectations. 

## Takeaway

### Patterns of interactions with AI

#### Calling or summoning AI
- AI appears proactively in context
- Users manually invoke the AI

#### Mutual learning
- The user and the system learn from each other

#### Building trust
* The system is as transparent as possible
* Helps the user understand AI capabilities and limitations

#### Generating
* The system generates content and ideas

#### Error prevention and handling
- Acknowledge errors and providing ways to handle them


## More references
* Microsoft's **[HAX Toolkit](https://www.microsoft.com/en-us/haxtoolkit/library/)** lays out guidelines for Human-AI Interaction (HAX) and includes patterns and examples to illustrate the guidelines.
* Google’s People + AI Guidebook’s **[Mental Models](https://pair.withgoogle.com/chapter/mental-models/)** explores co-learning and how AI and humans can onboard and teach each other.