* We must consider the larger picture and the impact of our work on immediate audience and humanity in general. *


# Video summary
- Now more than ever it is essential to keep people at the center of the design process. 
- Should we build this
- Does anyone need this
- And if the answer is yes, what are the ethical implications. 
- How do we make sure that our solution is inclusive, safe, sustainable. 
- Is it useful, do people need it
- How do we prevent it from causing harm
- We should move away from human-centered design to humanity centered design and even life centered design. 
- We should focus on the ecosystem of the planet, all living things
- We should solve a root issue, which is the problem as presented, often a symptom and not the cause. 
- We should all take a long term systems point of view and realize that the impact of our actions can take years to appear and even manifest decades later. 

# Article synthesis
- Consequence of design decisions: Social media
- Polarized society, with individuals living in a narrow echo chamber and who dont tolerate differing viewpoints. 
- Constant pressure to live a perfect life

# Framework for Designer - Data Scientist collaboration. 
* Google People + AI Research (PAIR) team
* Step by step framework for designing with AI


1. Do not expect AI to figure out what problems to solve. Use AI to
	* Research
	* Identify the root cause of problems. 
2. Ask if AI will address the problem in a unique way
	1. Technology is an enabler and not the end goal. 
	2. Consider a holistic solution and then ask yourself how can AI support it. 
3. Fake it with Wizard of Oz prototyping and testing with personal examples.
	1. Fake the AI with a real human acting in place of the AI
	2. When the model is ready, ask participants to bring in their own set of personal data. 
4. Weigh the costs of false positives and false negatives.
	1. To a machine, all errors are the same
	2. But people will experience errors differently. 
5. Plan for co-learning and adaptation. 
	1. Ai and humans continuously learn from one another. 
	2. Whenever we make changes to the model we must communicate them as well to the user. Use microsoft HAX toolkit. 
		1. Learn from user behavior
		2. Update and adapt cautiously
		3. Encourage granular feedback
		4. Notify users about changes. 
6. Teach the algorithm to use the right label. 
7. Work alongside datascientists and extend the design family

# The takeaway
- Human centered design in context of AI is not so different from traditional design. 
- We should still understand the users. 
- Empathy becomes a guiding principle to help design AI systems that function well but also respect human perspetives, are inclusive and avoid bias. 

# Resources
Learn about humanity-centered design and how to design _with_the community, not for them, in the course, **[Design for a Better World with Don Norman](https://www.interaction-design.org/courses/design-for-a-better-world-with-don-norman-course)**.

Read Jess Holbrook’s and Josh Lovejoy’s article, **[Human-Centered Machine Learning](https://medium.com/google-design/human-centered-machine-learning-a770d10562cd)**.

During the early days of AI, Josh Clark presented a set of guiding principles for designers to design data-driven products. The principles in this talk, **[Design in the Era of the Algorithm](https://bigmedium.com/speaking/design-in-the-era-of-the-algorithm.html)**stand true even as the technology has matured.

BBC’s report on **[Instagram being sued over harm to young people's mental health](https://www.bbc.com/news/business-67207829)**. 

See Laura Moreton and Sheila Greenfield’s research on **[University students’ views on the impact of Instagram on mental wellbeing](https://doi.org/10.1186/s40359-022-00743-6)**. 

Josh Lovejoy shares how human-centered design is still at the core of working with AI in this article, **[The UX of AI](https://design.google/library/ux-ai)**. 

**[Google’s Responsible AI Practices](https://ai.google/responsibility/responsible-ai-practices/)** offers recommendations related to Human-Centered Design, Fairness, Interpretability, Privacy, Safety and Security.

Use the 5 whys methods to go at the root of problems. 

![[21CD-5-whys-method.pdf]]