# Designing for trust
- Unique challenges
- Require transparent interfaces
- Clear feedback
- Ethical considerations

# Ensuring AI Solutions are reliable and that we can trust them. 

## Video notes

### Why there is mistrust around AI
- Behavior cannot be predicted most of the time. 
- Conventional UX is controllable because we understand and decide what happens next. 
- With AI: 
	- Communicate the risk upfront
	- Setting expectations about the performance
	- Indicating that the product will learn over time
	- Clarifying that mistakes will happen
	- Teach the user that their input will help to perform better. 
- Trust and transparency
	- We cannot trust what we cannot understand. 
	- What we cannot understand will feel like magic. 
- AI systems are not transparent to us for several reasons:
	- Most of us lack the technical knowledge to understand what is happening under the hood. 
	- Also many times we have no idea where the information is coming from. 
	- Answers from GPT and Bard can be totally made up and inaccurate. 
	- AI is not telling us how they constructed an answer although this would help. As designers we should push for this transparency. 
	- We should expose a high level thinking process that gives us the information sources and general reasoning behind an answer.

### AI in the media
- We have seen isolated but terrible experiences. 
- The solution might be to open up the language models for more transparency 
- Companies like google, facebook and twitter already released transparency reports. 
- Similar practice for AI. 

### Intellectual property and ownership
- There will be a shift in what we value as a society. 
- If we know something has been generated with AI we will probably not feel too much
- We will value what is human made. 
- We value what is generated from someone's experience, imagination, suffering, hope...  

# Article notes

## Building trust with users

1. We should be as transparent as possible
2. Communicate 
	1. Where does the system gets its data - Indicate sources when this is possible. 
	2. What user-generated information is used by the system. E.g. does the system rely on others to provide data?
	3. How does the system learn from user data?
	4. What are the chances of errors?
3. If the system relies on personal data (location, demographic information...)
	1. Collect this information with full consent
	2. Ask users to opt-in to share information instead of asking them to turn off the setting. 
	3. Allow users to use the solution without any personal data

## Characteristics of trustworthy AI Systems

Defined by the National Institute of Standards and Technology
* Valid and reliable
	* System's ability to meet users' needs
	* Keep performing without fail
	* Define success criteria and metrics to ensure the performance of the system
	* Assess the system to confirm it is performing as intended
* Safe
	* Never cause harm to users
	* Test and simulate real-world use to detect use-case where harm is caused and address it through design. 
* Secure and resilient
	* Performing under adverse or unexpected conditions 
	* Degrading safely and gracefully when it is necessary
	* Design a non-AI based solution to allow the user to continue using the solution in case the AI system breaks down
* Accountable and transparent
	* Status updates on its functioning
	* Information on its process
* Explainable and interpretable
	* Revealing how it works
	* Description tailored to users' roles, knowledge and skills level
* Privacy-enhanced
	* Safeguarding user freedom, identity and dignity
	* Tradeoff between privacy and bias. 
	* Being anonymous: Limit the inclusion of data needed for AI to function with minimal bias
* Fairness: Equality and eliminating discrimination. 

## Checklist for assessing AI systems
* Ensure it Meets Your Needs
	* Be clear about what you expect from the AI system.
	* Regularly assess if the system is delivering what you need without any issues.
* Keep Yourself Safe
	* Pay attention to warnings and alerts provided by the system.
	* Report any concerns about potential harm caused by the systemâ€™s suggestions or actions. 
* How Does it Function in Tough Situations?
	* Check if the system continues to work in unexpected situations.
	* Know what alternatives or fallback options are available if the AI encounters problems

## AI Art that sidesteps the copyright debate
- AI Generated art has huge potential for creative expression 
- Raises concern about transparency and ethics. 
- Providing transparency on the co-authorship of art
- Generative AI: Class of artifical inelligence algorithms and models designed to generate new content, such as images, text, music and more. 
- It operates by learning patterns and structures from large datasets. 
- Then when prompted it will give us an output similar to the training data but not exactly the same. 

### Controversy
- On one hand, technology makes us more democratic
- With AI, anyone with a vision can use AI to create art without the traditional skills to execute it. 
- Artists whose art is used to train AI can argue that it is a copyright infringement, particularly if the output from the AI system competes with the training dataset. 
- Unsupervised: Constantly changing animation of abstract visual based on the interpretation of the machine of MoMa collection. 
- Use information from the weather, and live visitors' feed visiting the museum. 
- Gives the illusion that it is living. 

### Takeaway
- Essential to clearly communicate the data sources, how the system learns and the probability of errors
- Trustworthy AI system: 
	- Valid and reliable
	- Meeting user needs
	- Performing consistently 
	- Safety
	- Rigorous testing
	- Collaboration between designers, data scientists, designers and developpers
	- Accountability and transparency: regular status updates and clear insights into system's processes. 
	- Explainability and interpretability make the system understandable
	- Privacy enhanced AI: 
		- Balance between privacy and data incusivity. 
		- Fairness: Manage biases

# Resources
[[Obsidian/01 ðŸ’¼ Projects/AI For Designers/Resources|Resources]]
![[Lesson 4.3 - Resource - check-your-ai-tools-reliability.pdf]]



> [!Information] Information
> If users expect deterministic experience from a probabilistic system, their experience will be degraded. 


